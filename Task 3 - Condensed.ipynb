{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 3 - Condensed Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as sk\n",
    "from sklearn import preprocessing\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest,mutual_info_classif , f_classif\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import f1_score, accuracy_score, roc_auc_score\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./data.csv', index_col=0)\n",
    "\n",
    "# Category indexing\n",
    "i_voltage = np.arange(0,9)\n",
    "i_angles= np.arange(9,18)\n",
    "i_pgen = np.arange(18,27)\n",
    "i_qgen = np.arange(27,36)\n",
    "i_pdem = np.arange(36,45)\n",
    "i_qdem = np.arange(45,54)\n",
    "i_pflow = np.arange(54, 135)\n",
    "i_qflow = np.arange(135, 216)\n",
    "i_risk = 216\n",
    "\n",
    "data_raw= pd.concat([data.iloc[:, i_voltage], data.iloc[:, i_angles],\n",
    "                data.iloc[:, i_pgen], data.iloc[:, i_qgen], data.iloc[:, i_pdem], \n",
    "                     data.iloc[:, i_qdem], data.iloc[:, i_pflow], data.iloc[:, i_qflow], data.iloc[:, i_risk]], axis=1)\n",
    "\n",
    "#dataset1\n",
    "data_raw = data_raw.loc[:, data_raw.any()].dropna(axis=0)\n",
    "X1 = data_raw.iloc[:, 0:(data_raw.shape[1]-1)]\n",
    "y1 = data_raw.iloc[:, (data_raw.shape[1]-1)]\n",
    "y_1=y1.to_numpy()\n",
    "for i in range(0,np.shape(y_1)[0]):\n",
    "    if y_1[i]<0.1:\n",
    "        y_1[i]=0\n",
    "    elif y_1[i]<0.35:\n",
    "        y_1[i]=1\n",
    "    elif y_1[i]<0.7:\n",
    "        y_1[i]=2\n",
    "    else:\n",
    "        y_1[i]=3\n",
    "le = preprocessing.LabelEncoder()\n",
    "y_1=le.fit_transform(y_1)\n",
    "x_1=X1.to_numpy()\n",
    "\n",
    "#dataset2\n",
    "data_raw= pd.concat([data.iloc[:, i_voltage], data.iloc[:, i_angles],\n",
    "                data.iloc[:, i_pgen], data.iloc[:, i_qgen], data.iloc[:, i_pdem], \n",
    "                     data.iloc[:, i_qdem], data.iloc[:, i_pflow], data.iloc[:, i_qflow], data.iloc[:, i_risk]], axis=1)\n",
    "data_raw = data_raw.loc[:, data_raw.any()]\n",
    "X2raw = data_raw.iloc[:, 0:(data_raw.shape[1]-1)]\n",
    "y2 = data_raw.iloc[:, (data_raw.shape[1]-1)]\n",
    "imputer = IterativeImputer(random_state=4720)\n",
    "X2 = imputer.fit_transform(X2raw)\n",
    "y_2=y2.to_numpy()\n",
    "for i in range(0,np.shape(y_2)[0]):\n",
    "    if y_2[i]<0.1:\n",
    "        y_2[i]=0\n",
    "    elif y_2[i]<0.35:\n",
    "        y_2[i]=1\n",
    "    elif y_2[i]<0.7:\n",
    "        y_2[i]=2\n",
    "    else:\n",
    "        y_2[i]=3\n",
    "y_2=le.fit_transform(y_2)\n",
    "x_2=X2\n",
    "\n",
    "#Train and Test Split\n",
    "X_1train, X_1test, y_1train, y_1test = train_test_split(x_1, y_1, test_size=0.2, random_state=4720)\n",
    "X_2train, X_2test, y_2train, y_2test = train_test_split(x_2, y_2, test_size=0.2, random_state=4720)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipeline 1 - Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtpipe = Pipeline([\n",
    "    #('Dimensionality',PCA(n_components=30,whiten='True')),\n",
    "    ('Kbest', SelectKBest(score_func=f_classif, k=25)),\n",
    "    ('DT', DecisionTreeClassifier(max_depth=None,random_state=4720))\n",
    "])\n",
    "\n",
    "dtparam={\n",
    "    #'Dimensionality__n_components':[30],#None],\n",
    "    #'Dimensionality__whiten':['True'],#'False'],\n",
    "    'Kbest__score_func':[mutual_info_classif,f_classif],\n",
    "    'Kbest__k':[10,15,20,25],#10,20,30],\n",
    "    'DT__max_depth': [12,15,17,20] #2,5\n",
    "}\n",
    "\n",
    "dtsearch = RandomizedSearchCV(dtpipe, dtparam, cv=5,scoring='f1_weighted')\n",
    "\n",
    "dtsearch.fit(X_1train,y_1train)\n",
    "bestmodel=dtsearch.best_estimator_\n",
    "y_predict=bestmodel.predict(X_1test)\n",
    "print('Weighted F1 score for dataset 1 is: %.5f'%f1_score(y_1test,y_predict,average='weighted'))\n",
    "dtsearch.best_params_\n",
    "dtsearch.best_estimator_\n",
    "\n",
    "dtsearch.fit(X_2train,y_2train)\n",
    "bestmodel=dtsearch.best_estimator_\n",
    "y_predict=bestmodel.predict(X_2test)\n",
    "print('Weighted F1 score for dataset 2 is: %.5f'%f1_score(y_2test,y_predict,average='weighted'))\n",
    "dtsearch.best_params_\n",
    "dtsearch.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipeline 2 - Extra-trees Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "etpipe = Pipeline([\n",
    "    #('Dimensionality',PCA(n_components=30,whiten='True')),\n",
    "    ('Kbest', SelectKBest(score_func=f_classif, k=25)),\n",
    "    ('ET', ExtraTreesClassifier(max_depth=None,random_state=4720))\n",
    "])\n",
    "\n",
    "etparam={\n",
    "    #'Dimensionality__n_components':[None],#40\n",
    "    #'Dimensionality__whiten':['True'],#'False'],\n",
    "    'Kbest__score_func':[mutual_info_classif,f_classif],\n",
    "    'Kbest__k':[30,40,50,60],#10,20,30],\n",
    "    'ET__max_depth': [10,15,25,30] #2,5,10\n",
    "}\n",
    "\n",
    "etsearch = RandomizedSearchCV(etpipe, etparam, cv=5,scoring='f1_weighted')\n",
    "\n",
    "etsearch.fit(X_1train,y_1train)\n",
    "bestmodel=etsearch.best_estimator_\n",
    "y_predict=bestmodel.predict(X_1test)\n",
    "print('Weighted F1 score for dataset 1 is: %.5f'%f1_score(y_1test,y_predict,average='weighted'))\n",
    "etsearch.best_params_\n",
    "etsearch.best_estimator_\n",
    "\n",
    "etsearch.fit(X_2train,y_2train)\n",
    "bestmodel=etsearch.best_estimator_\n",
    "y_predict=bestmodel.predict(X_2test)\n",
    "print('Weighted F1 score for dataset 2 is: %.5f'%f1_score(y_2test,y_predict,average='weighted'))\n",
    "etsearch.best_params_\n",
    "etsearch.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipeline 3 - SVM linearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spipe=Pipeline([\n",
    "    ('Scaling', MinMaxScaler()),\n",
    "    ('Dimensionality',PCA(n_components=30,whiten='True')),\n",
    "    #('Kbest', SelectKBest(score_func=f_classif, k=25)),\n",
    "    ('linearSVC',LinearSVC(C=1,multi_class='ovr',random_state=4720))\n",
    "])\n",
    "\n",
    "sparam={\n",
    "    'Dimensionality__n_components':[50,60],#40,45\n",
    "    'Dimensionality__whiten':['True','False'],\n",
    "    #'Kbest__score_func':[mutual_info_classif],\n",
    "    #'Kbest__k':[30,40,50],#10,20,30],\n",
    "    'linearSVC__C': [0.1,1,10], #2,5,10\n",
    "}\n",
    "\n",
    "svsearch = RandomizedSearchCV(spipe, sparam, cv=5,scoring='f1_weighted')\n",
    "\n",
    "svsearch.fit(X_1train,y_1train)\n",
    "bestmodel=svsearch.best_estimator_\n",
    "y_predict=bestmodel.predict(X_1test)\n",
    "print('Weighted F1 score for dataset 1 is: %.5f'%f1_score(y_1test,y_predict,average='weighted'))\n",
    "svsearch.best_params_\n",
    "svsearch.best_estimator_\n",
    "\n",
    "svsearch.fit(X_2train,y_2train)\n",
    "bestmodel=svsearch.best_estimator_\n",
    "y_predict=bestmodel.predict(X_2test)\n",
    "print('Weighted F1 score for dataset 2 is: %.5f'%f1_score(y_2test,y_predict,average='weighted'))\n",
    "svsearch.best_params_\n",
    "svsearch.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipeline 4 - SVM SVC-RBF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spipe2=Pipeline([\n",
    "    ('Scaling', StandardScaler()),\n",
    "    #('Dimensionality',PCA(n_components=45,whiten='True')),\n",
    "    ('Kbest', SelectKBest(score_func=mutual_info_classif, k=35)),\n",
    "    ('RBFSVC',SVC(C=1,kernel='rbf',random_state=4720, gamma='auto'))\n",
    "])\n",
    "\n",
    "sparam2={\n",
    "    #'Dimensionality__n_components':[45],#40,45\n",
    "    #'Dimensionality__whiten':['True'],#'False'],\n",
    "    'Kbest__score_func':[mutual_info_classif,f_classif],\n",
    "    'Kbest__k':[25,35,40],#10,20,30],\n",
    "    'RBFSVC__C': [1,10,100,1000], #2,5,10\n",
    "    'RBFSVC__gamma': ['auto','scale']\n",
    "}\n",
    "\n",
    "svsearch2 = RandomizedSearchCV(spipe2, sparam2, cv=5,scoring='f1_weighted')\n",
    "\n",
    "svsearch2.fit(X_1train,y_1train)\n",
    "bestmodel=svsearch2.best_estimator_\n",
    "y_predict=bestmodel.predict(X_1test)\n",
    "print('Weighted F1 score for dataset 1 is: %.5f'%f1_score(y_1test,y_predict,average='weighted'))\n",
    "svsearch2.best_params_\n",
    "svsearch2.best_estimator_\n",
    "\n",
    "svsearch2.fit(X_2train,y_2train)\n",
    "bestmodel=svsearch2.best_estimator_\n",
    "y_predict=bestmodel.predict(X_2test)\n",
    "print('Weighted F1 score for dataset 2 is: %.5f'%f1_score(y_2test,y_predict,average='weighted'))\n",
    "svsearch2.best_params_\n",
    "svsearch2.best_estimator_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipeline 5 - K-nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kpipe=Pipeline([\n",
    "    ('Scaling', StandardScaler()),\n",
    "   # ('Dimensionality',PCA(n_components=45,whiten='True')),\n",
    "    ('Kbest', SelectKBest(score_func=mutual_info_classif, k=25)),\n",
    "    ('KNN',KNeighborsClassifier(n_neighbors=10, leaf_size=20, weights='distance'))\n",
    "])\n",
    "\n",
    "kparam={\n",
    "    #'Dimensionality__n_components':[45],\n",
    "    #'Dimensionality__whiten':['True'],\n",
    "    'Scaling':[StandardScaler(),MinMaxScaler()],\n",
    "    'Kbest__score_func':[mutual_info_classif,f_classif],\n",
    "    'Kbest__k':[10,15,20,25,30,35],\n",
    "    'KNN__n_neighbors': [5,10,15], \n",
    "    'KNN__leaf_size':[5,8,10,15],#25,30\n",
    "    'KNN__weights':['distance','uniform']#uniform\n",
    "}\n",
    "\n",
    "ksearch = RandomizedSearchCV(kpipe, kparam, cv=5,scoring='f1_weighted')\n",
    "\n",
    "ksearch.fit(X_1train,y_1train)\n",
    "bestmodel=ksearch.best_estimator_\n",
    "y_predict=bestmodel.predict(X_1test)\n",
    "print('Weighted F1 score for dataset 1 is: %.5f'%f1_score(y_1test,y_predict,average='weighted'))\n",
    "ksearch.best_params_\n",
    "ksearch.best_estimator_\n",
    "\n",
    "ksearch.fit(X_2train,y_2train)\n",
    "bestmodel=ksearch.best_estimator_\n",
    "y_predict=bestmodel.predict(X_2test)\n",
    "print('Weighted F1 score for dataset 2 is: %.5f'%f1_score(y_2test,y_predict,average='weighted'))\n",
    "ksearch.best_params_\n",
    "ksearch.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipeline 6 - Deep Learning Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7c7d8d1319027f156a5671dbeeb81040a290cf2e1fde3b933d4abdbe59e01056"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
